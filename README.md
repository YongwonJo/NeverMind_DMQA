# NeverMind_DMQA
This repository contains key summary and description files for various papers.

## Members
The member consists of 8 researchers belonging to the Data Mining & Quality Analytics (DMQA) lab. [[website]](http://dmqa.korea.ac.kr/) \
**If you have any questions, please contact us by email of the researcher who prepared the material.**

* Young Jae Lee
  * Ph.D. Student / Email: jae601@korea.ac.kr
  
* Yongwon Jo
  * Ph.D. Student / Email: gyj4318@korea.ac.kr
  
* Jinhyeok Park
  * Ph.D. Student / Email: vc2013@korea.ac.kr
  
* Jaehoon Kim
  * Ph.D. Student / Email: jhoon0418@korea.ac.kr
  
* Saerin Lim
  * M.S. Student / Email: momo_om@korea.ac.kr
  
* Jongkook Heo
  * M.S. Student / Email: hjkso1406@korea.ac.kr
  
* Eunji Koh
  * M.S. Student / Email: ejkoh21@korea.ac.kr
  
* Leekyung Yoo
  * M.S. Student / Email: ylk0801@korea.ac.kr

## Vision Transformer
Key Summary and Description of Paper on Vision Transformer

* 2021-07-02
  * Young Jae Lee / Visual Transformers: Token-based Image Representation and Processing for Computer Vision [[paper]](https://arxiv.org/abs/2006.03677)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210702/%5B20210702%5DVisual%20Transformers%20-%20Token-based%20Image%20Representation%20and%20Processing%20for%20Computer%20Vision.pdf)
  * Saerin Lim / TransGAN: Two Transformers Can Make One Strong GAN [[paper]](https://arxiv.org/abs/2102.07074)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210702/%5B20210702%5DTransGAN-Two%20Transformers%20Can%20Make%20One%20Strong%20GAN.pdf)


* 2021-07-09
  * Jaehoon Kim / Rethinking Spatial Dimensions of Vision Transformers [[paper]](https://arxiv.org/abs/2103.16302)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210709/%5B20210709%5DRethinking%20Spatial%20Dimensions%20of%20Vision%20Transformers.pdf)
  * Jongkook Heo / Emerging Properties in Self-Supervised Vision Transformers [[paper]](https://arxiv.org/abs/2104.14294)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210709/%5B20210709%5DEmerging%20Properties%20in%20Self-Supervised%20Vision%20Transformer.pdf)

* 2021-07-16
  * Yongwon Jo / Inpainting Transformer for Anomaly Detection [[paper]](https://arxiv.org/abs/2104.13897)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210716/%5B20210716%5D%20Inpainting%20Tranformer%20for%20Anomaly%20Detection.pdf)
  * Eunji Koh / Training Data-Efficient Image Transformers & Distillation through Attention [[paper]](http://proceedings.mlr.press/v139/touvron21a.html)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210716/%5B20210716%5DTraining%20data-efficient%20image%20transformers%20%26%20distillation%20through%20attention.pdf)

* 2021-07-23
  * Jinhyeok Park / End-to-End Object Detection with Transformers [[paper]](https://arxiv.org/abs/2005.12872)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210723/%5B20210723%5DEnd%20to%20End%20Object%20Detection%20with%20Transformers.pdf)
  * Leekyung Yoo / Mlp-Mixer: An All-Mlp Architecture for Vision [[paper]](https://arxiv.org/abs/2105.01601)[[presentation]](https://github.com/dudwojae/NeverMind_DMQA/blob/main/VisionTransformer/20210723/%5B20210723%5DMLP-Mixer%20-%20An%20all-MLP%20Architecture%20for%20Vision.pdf)

* 2021-07-30
  * Young Jae Lee / Swin Transformer: Hierarchical Vision Transformer using Shifted Windows [[paper]](https://arxiv.org/abs/2103.14030)
  * Saerin Lim / SiT: Self-supervised vIsion Transformer [[paper]](https://arxiv.org/abs/2104.03602)
